---
title       : GARCH and MA Outperformance using rCharts & d3 Parallel Coordinates
subtitle    : Applied to French Industry Data Set
author      : TimelyPortfolio
framework   : minimal       # {io2012, html5slides, shower, dzslides, ...}
github: {user: timelyportfolio, repo: rCharts_d3_parcoords, branch: "gh-pages"}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : [parcoords]      # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
assets:
  css: 
    - "http://fonts.googleapis.com/css?family=Open+Sans"
    - "http://fonts.googleapis.com/css?family=Open+Sans+Condensed:700"
---


---
# GARCH and MA Outperformance
## Now Using d3 Parallel Coordinates with rCharts

Parallel coordinates become much more useful when they are interactive, so I will recreate one of my favorite blog posts ["Trend is Not Your Friend" Applied to 48 Industries](http://timelyportfolio.blogspot.com/2012/08/trend-is-not-your-friend-applied-to-48.html) and convert the chart to a living breathing d3 parallel coordinates chart courtesy of [Ramnath Vaidyanathan's rCharts](http://ramnathv.github.io/rCharts/) and [Kai Chang's d3.parcoords](http://syntagmatic.github.io/parallel-coordinates/). I will convert the scatter and horizon plots in a later post.  Note see 

<!--old post; left in html to demonstrate combination-->
# "Trend is Not Your Friend" Applied to 48 Industries
<p><em><font size="1">Please see previous post <a href="http://timelyportfolio.blogspot.com/2012/06/crazy-rut-in-academic-context.html">Crazy RUT in Academic Context Why Trend is Not Your Friend</a>.</font></em></p>
  <p>I'll repeat the intro to the post mentioned above, so we can all get caught back up.</p>
  <p>In response to <a href="http://timelyportfolio.blogspot.com/2012/06/where-are-fat-tails.html">Where are the Fat Tails?</a>, reader vonjd very helpfully referred me to this paper <a href="http://www.frankfurt-school.de/clicnetclm/fileDownload.do?goid=000000311260AB4" target="_blank">The Trend is Not Your Friend! Why Empirical Timing Success is Determined by the Underlying's Price Characteristics and Market Efficiency is Irrelevant</a> by Peter Scholz and Ursula Walther. The authors conclude</p>
  <blockquote>
  <p>"Our study on the basis of real data clearly confirms the hypothesis that the asset price characteristics of the underlying price process have a crucial impact on timing results. This allows us to forecast the timing success depending on the market's parameters. An OLS regression analysis supports our predictions and verifies our assumption that the drift has the<br>strongest influence on timing success. By contrast, the higher moments (skewness, kurtosis) seem not to have any significant impact on the timing result in the empirical sample. As we presumed, the level of market development, and hence the degree of efficiency, does not play any role. Trading worked coincidentally rather well in the developed world and quite poorly in the emerging markets. The driving factor for the timing success is the parametric environment the trading system stumbles on.</p>
<p>Our study contributes to the discussion by providing a structured analysis of the relevance of the most important price process parameters. As a result, the traditional explanations for timing success can be abandoned: we find that it is very likely for the SMA trading rule to generate excess returns over its benchmark if the underlying price path exhibits negative drifts, high serial autocorrelation, low volatilities of returns, and highly clustered volatilities. Drift and autocorrelation of the underlying asset seem to have the largest impact, though."</p></blockquote>
<p>One of my initial ideas for extending the research was to incorporate a much larger set of indexes over a longer period of time.&nbsp; As I was working on <a href="http://timelyportfolio.blogspot.com/2012/08/48-industries-since-1963.html">48 Industries Since 1963</a>, I decided 50 years of data on 48 different indexes would be a great dataset to apply the ideas and methods presented in the paper.</p>
<p>Using R and all its wonderful packages, it is surprisingly easy to accomplish.&nbsp; Let's see if we can test "drift and autocorrelation.have the largest impact" on excess returns with industries also.&nbsp; I'll try not to get too statistical.</p>
<p>In terms of drift or annualized return, we can see a linear inverse relationship between return and out(under)performance of the 200 day moving average system, so the better the performance of the industry, the less likely a moving average system is to outperform.</p>
<table style="width: auto">
<tbody>
<tr>
<td><a href="https://picasaweb.google.com/lh/photo/DYGUjcUGkmrHlaVDDQCZj9MTjNZETYmyPJy0liipFm0?feat=embedwebsite"><img src="https://lh3.googleusercontent.com/-9blyMbBqm0I/UCKl39NZYhI/AAAAAAACrPw/vZiS_PZc2dA/s800/Rplot.png" width="640" height="500"></a></td></tr>
<tr>
<td style="text-align: right; font-family: arial,sans-serif; font-size: 11px">From <a href="https://picasaweb.google.com/115099029813395778077/TimelyPortfolio02?authuser=0&amp;feat=embedwebsite">TimelyPortfolio</a></td></tr></tbody></table>
<p>In terms of the GARCH model effects on excess returns, a parallel coordinate chart will best start our exploration.&nbsp; Lines are colored by the excess return of a moving average system on each industry.</p>

```{r results ="asis", echo = FALSE, message = FALSE, warnings = FALSE}
require(rCharts)

#get very helpful Ken French data
#for this project we will look at Industry Portfolios
#http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/48_Industry_Portfolios_daily.zip

require(latticeExtra)
require(PerformanceAnalytics)
require(quantmod)

#my.url will be the location of the zip file with the data
my.url="http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/48_Industry_Portfolios_daily.zip"
#this will be the temp file set up for the zip file
my.tempfile<-paste(tempdir(),"\\frenchindustry.zip",sep="")
#my.usefile is the name of the txt file with the data
my.usefile<-paste(tempdir(),"\\48_Industry_Portfolios_daily.txt",sep="")
download.file(my.url, my.tempfile, method="auto", 
              quiet = FALSE, mode = "wb",cacheOK = TRUE)
unzip(my.tempfile,exdir=tempdir(),junkpath=TRUE)
#read space delimited text file extracted from zip
french_industry <- read.table(file=my.usefile,
                              header = TRUE, sep = "",
                              as.is = TRUE,
                              skip = 9, nrows=22881)

#get dates ready for xts index
datestoformat <- rownames(french_industry)
datestoformat <- paste(substr(datestoformat,1,4),
                       substr(datestoformat,5,6),substr(datestoformat,7,8),sep="-")

#get xts for analysis
french_industry_xts <- as.xts(french_industry[,1:NCOL(french_industry)],
                              order.by=as.Date(datestoformat))

#divide by 100 to get percent
french_industry_xts <- french_industry_xts/100

#delete missing data which is denoted by -0.9999
french_industry_xts[which(french_industry_xts < -0.99,arr.ind=TRUE)[,1],
                  unique(which(french_industry_xts < -0.99,arr.ind=TRUE)[,2])] <- NA
french_industry_xts <- na.omit( french_industry_xts )

#get price series or cumulative growth of 1
french_industry_price <- cumprod(french_industry_xts+1)

#do 200 day moving average for initial testing
#just change n to test on other widths or rolling period
ma <- as.xts(apply(french_industry_price, MARGIN = 2, FUN = runMean, n=200), order.by = index(french_industry_price))

#set up system to enter when price moves above moving average
#exit when below
ma.system <- lag(as.xts(
                  apply(french_industry_price > ma, MARGIN = 2, as.numeric),
                  order.by = index(french_industry_price)),
                 k=1) * french_industry_xts

#get returns cumulative and annualized for the entire period
ret.comp.cumul <- Return.cumulative(ma.system) - Return.cumulative(french_industry_xts)
ret.bh.ann <- Return.annualized(french_industry_xts)
ret.comp.ann <- Return.annualized(ma.system) - ret.bh.ann
rownames(ret.comp.ann) <- "Out(under)performance"


#get colors to use for heat map style coloring by out/under performance
brew <- brewer.pal(name="RdBu",n=5)
#get color ramp
cc.brew <- colorRampPalette(brew)
#apply color ramp
cc <- cc.brew(length(ret.comp.ann))
#do colors based on out/under performance but with gray so visible when labelling
cc.palette <- colorRampPalette(c(cc[1],"gray60",cc[length(cc)]))
cc.levpalette <- cc.palette(length(ret.comp.ann))
cc.levels <- level.colors(ret.comp.ann, at = do.breaks(c(-max(abs(ret.comp.ann)),max(abs(ret.comp.ann))),length(ret.comp.ann)),
                          col.regions = cc.levpalette)



#using rugarch get garch stats similar to those explored in the research
require(rugarch)
spec = ugarchspec(
  variance.model=list(garchOrder=c(1,1)),
  mean.model=list(armaOrder=c(1,1), include.mean=T))

#set up function to get garch stats through apply function
gfNa <- function(data, spec) {
  x <- na.omit(coredata(data))
  gf <- suppressWarnings(ugarchfit(spec=spec, data=x))
  stats <- if (is.null( coef( gf ) ) )  {
    t(rep(NA, 6)) } else t( coef( gf ) )
  stats <- data.frame( stats )
  colnames( stats ) <- c( "mu", "ar1", "ma1", "omega", "alpha1", "beta1" )
  return(stats)
}

#apply fails so convert to for loop
#do apply to get garch stats across all industries
#gf.stats <- apply(french_industry_xts[,1:3],MARGIN=2,FUN=gfNa,spec=spec)
gf.stats <- data.frame()

for (i in 1:NCOL( french_industry_xts) ) {
  gf.stats <- rbind(
    gf.stats,
    cbind(
      colnames( french_industry_xts )[i],
      gfNa ( french_industry_xts[,i], spec = spec )
    )
  )
}  

colnames( gf.stats )[1] <- c("industry")
rownames( gf.stats ) <- gf.stats$industry

#add the column for return out (under) performance
gf.stats$PerfDiff <- as.numeric( ret.comp.ann )

#show off a little with R
#order by dendrogram
require(timeSeries)
dist = dist(t(series(as.timeSeries(french_industry_xts))))
t = hclust(dist)
gf.stats <- gf.stats[t$order,]

cat( noquote( "<h3>d3 Parallel Coordinates (go ahead and play with it)</h3>") )
cat( noquote( '<div style="height:600px">\n' ) )
p1 <- rCharts$new()
p1$field('lib', 'libraries/widgets/parcoords')
p1$set(
  padding = list(top = 24, left = 100, bottom = 12, right = 200),
  height = "600"
)
#get range of data
#for colors to be right need min and max to be same so 0 is center
maxabs <- max(abs(range(gf.stats$PerfDiff)))
p1$set(data = toJSONArray(gf.stats, json = F), 
  colorby = 'PerfDiff', 
  range = c( -maxabs, 0, maxabs ),
  colors = c( 
    paste0( max( cc.levels) ),
    'gray',
    paste0( min( cc.levels) )
  )
)
p1
p1$print('chart')
cat( noquote( '</div>' ) )
cat( noquote( "<h3>Old Static R Parallel Coordinates (not as helpful)</h3>") )

require(MASS)
parcoord(x = gf.stats[, -1],
         col = cc.levels,lwd = 2,
         main = "Out(under)Performance by GARCH Stat")

cat( noquote('<p>Mu and alpha1 seem to most heavily influence the ability of a moving average system to outperform.&nbsp; Let us isolate our chart to mu and alpha1 and add ar1 based on the findings of the authors.&nbsp; I am very tempted to try to explain GARCH here, but for the sake of brevity, I will refrain.&nbsp; This <a href="http://scholar.google.com/scholar?cluster=1570505569310094643&amp;hl=en&amp;as_sdt=0,1" target="_blank">paper</a> and this <a href="http://www.portfolioprobe.com/2012/07/06/a-practical-introduction-to-garch-modeling/" target="_blank">Portfolio Probe post</a> offer a good introduction to GARCH.</p>\n' ) )

#do static parallel coordinates chart with color

parcoord(x = gf.stats[,c(8,2,3,6)],
         col = cc.levels,lwd = 2,
         main = "Out(under)Performance by GARCH Stat")

#get rolling out(under) performance for horizon chart
#change na to 0 in ma.system returns
ma.system[which(is.na(ma.system),arr.ind=TRUE)[,1],
          unique(which(is.na(ma.system),arr.ind=TRUE)[,2])] <- 0
ma_system_price <- cumprod(1+ma.system)
roc <- french_industry_price
#split into groups so do not run out of memory
for (i in seq(12,48,by=12)) {
  #get difference in rolling performance
  roc[,((i-11):(i))] <- ROC(ma_system_price[,((i-11):(i))],n=250,type="discrete") -
    ROC(french_industry_price[,((i-11):(i))],n=250,type="discrete")
}
roc[1:250,] <- 0


cat( noquote( '<p>In conclusion, it seems the same effects observed by the authors also apply to US industry indexes.&nbsp; In future posts, I will add a little more statistical rigor to the analysis and apply to other indexes.</p>
<p>Now, I just cannot resist using a horizon plot to evaluate the rolling 250 day excess returns of a moving average system over buy and hold.&nbsp; As you can see, a bull market favors buy and hold.&nbsp; The 70s and 2008-2009 were very kind to a moving average approach.</p>\n'  ) )

cat( noquote( "<h3>Old Static R Horizon Plot</h3>") )

#do a horizon plot of all 48 industries with horizonscale of 0.25
horizonplot(roc,
            layout=c(1,48),
            horizonscale=0.25,    #feel free to change to whatever you would like
            scales = list(tck = c(1,0), y = list(draw = FALSE,relation = "same")),
            origin = 0,
            colorkey = FALSE,
            #since so many industries, we will comment out grid
            #            panel = function(x, ...) {
            #              panel.horizonplot(x, ...)
            #              panel.grid(h=3, v=0,col = "white", lwd=1,lty = 3)
            #            },
            ylab = list(rev(colnames(roc)), rot = 0, cex = 0.7, pos = 3), 
            xlab = NULL,
            par.settings=theEconomist.theme(box = "gray70"),
            #use ylab above for labelling so we can specify FALSE for strip and strip.left
            strip = FALSE,
            strip.left = FALSE,
            main = "Moving Averages System Performance on French Daily 48 Industry 1963-2011\n source: http://mba.tuck.dartmouth.edu/pages/faculty/ken.french")

```

